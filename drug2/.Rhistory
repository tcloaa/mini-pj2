#validation on model
x_test= as.matrix(kaggle_data[,3:ncol(kaggle_data)])
predict_value = predict(temp_fit, newx=x_test, s="lambda.min")
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission.csv", sep = ",", qmethod = "double", row.names = FALSE)
View(output_file)
library(glmnet)
#training data
x_train= as.matrix(model_data[,3:ncol(model_data)])
y_train= as.matrix((model_data[,2, drop = FALSE]))
#create model
temp_fit = cv.glmnet(x_train, y_train, alpha = 1, parallel = TRUE)
#validation on model
x_test= as.matrix(kaggle_data[,3:ncol(kaggle_data)])
predict_value = predict(temp_fit, newx=x_test, s="lambda.min")
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(glmnet)
#training data
x_train= as.matrix(model_data[,3:ncol(model_data)])
y_train= as.matrix((model_data[,2, drop = FALSE]))
#create model
temp_fit = cv.glmnet(x_train, y_train, standardize=TRUE, alpha = 1, parallel = TRUE)
#validation on model
x_test= as.matrix(kaggle_data[,3:ncol(kaggle_data)])
predict_value = predict(temp_fit, newx=x_test, s="lambda.min")
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission.csv", sep = ",", qmethod = "double", row.names = FALSE)
View(output_file)
View(x_train)
par(mfrow =c(1,2))
plot(list, mse_bagging,type="l",col="red",main="bagging", xlab = "num of trees")
plot(list, mse_rf,type="l",col="black", main="random forest", xlab = "num of trees")
View(y_train)
View(x_train)
library(gbm)
boost1 = gbm(IC50s ~ . - Cell.lines, data = model_data, distribution = "gaussian", n.trees = 5000, interaction.depth = 1)
predict_value = predict(boost1, newdata = kaggle_data, n.trees = 5000)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission.csv", sep = ",", qmethod = "double", row.names = FALSE)
require(doMC)
library(data.table)
registerDoMC(cores=4)
source <- read.csv(file="train.csv", header=TRUE, sep=",", stringsAsFactors=FALSE)
rownames(source) <- source[,1]
source[,1] <- NULL #eliminate variable "ID"
source <- data.frame(source)
model_data = source[which(is.na(source["IC50s"])== FALSE),] #542 data
kaggle_data = source[which(is.na(source["IC50s"])== TRUE),] #100 data
output_file <- read.csv(file="submission.csv", header=TRUE, sep=",", stringsAsFactors=FALSE)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = ncol(model_data))
predict_value = predict(forest1, newdata = kaggle_data)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(gbm)
boost1 = gbm(IC50s ~ . - Cell.lines, data = model_data, distribution = "gaussian", n.trees = 5000, interaction.depth = 1)
predict_value = predict(boost1, newdata = kaggle_data, n.trees = 5000)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(gbm)
boost1 = gbm(IC50s ~ . - Cell.lines, data = model_data, distribution = "gaussian", n.trees = 5000, interaction.depth = 1)
predict_value = predict(boost1, newdata = kaggle_data, n.trees = 5000)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(randomForest)
true_y = model_data$IC50s
max_tree_num = 5000
list = seq(1, max_tree_num, by = 100)
mse_bagging = rep(0, length(list))
mse_rf = rep(0, length(list))
mse_boosting = rep(0, length(list))
for (i in c(1:length(list))) {
#bagging
bagging_model = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = ncol(model_data), n.trees = list[i])
mse_bagging[i] = mean(( true_y - predict(bagging_model, newdata = model_data))^2)
#forest
rf_model = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = ncol(model_data)^0.5, n.trees = list[i])
mse_rf[i] = mean(( true_y - predict(rf_model, newdata = model_data))^2)
#boosting
boost1 = gbm(IC50s ~ . - Cell.lines, data = model_data, distribution = "gaussian", n.trees = list[i], interaction.depth = 1)
mse_boosting[i] = mean(( true_y - predict(boost1, newdata = model_data, n.trees = list[i]))^2)
print(i)
}
par(mfrow =c(3,1))
plot(list, mse_bagging,type="l",col="red",main="bagging", xlab = "num of trees")
plot(list, mse_rf,type="l",col="black", main="random forest", xlab = "num of trees")
plot(list, mse_boosting,type="l",col="green", main="boosting", xlab = "num of trees")
par(mfrow =c(3,1))
plot(list, mse_bagging,type="l",col="red",main="bagging", xlab = "num of trees")
plot(list, mse_rf,type="l",col="black", main="random forest", xlab = "num of trees")
plot(list, mse_boosting,type="l",col="green", main="boosting", xlab = "num of trees")
par(mfrow =c(1,3))
plot(list, mse_bagging,type="l",col="red",main="bagging", xlab = "num of trees")
plot(list, mse_rf,type="l",col="black", main="random forest", xlab = "num of trees")
plot(list, mse_boosting,type="l",col="green", main="boosting", xlab = "num of trees")
mse_boosting
library(randomForest)
true_y = model_data$IC50s
max_tree_num = 5000
list = seq(1, max_tree_num, by = 100)
mse_bagging = rep(0, length(list))
mse_rf = rep(0, length(list))
mse_rf2 = rep(0, length(list))
mse_boosting = rep(0, length(list))
for (i in c(1:length(list))) {
#bagging
bagging_model = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = ncol(model_data), n.trees = list[i])
mse_bagging[i] = mean(( true_y - predict(bagging_model, newdata = model_data))^2)
#forest 1
rf_model = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = ncol(model_data)^0.5, n.trees = list[i])
mse_rf[i] = mean(( true_y - predict(rf_model, newdata = model_data))^2)
#forest 2
rf_model_2 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = 25, n.trees = list[i])
mse_rf2[i] = mean(( true_y - predict(rf_model_2, newdata = model_data))^2)
#boosting
boost1 = gbm(IC50s ~ . - Cell.lines, data = model_data, distribution = "gaussian", n.trees = list[i], interaction.depth = 1)
mse_boosting[i] = mean(( true_y - predict(boost1, newdata = model_data, n.trees = list[i]))^2)
print(i)
}
par(mfrow =c(1,4))
plot(list, mse_bagging,type="l",col="red",main="bagging", xlab = "num of trees")
plot(list, mse_rf,type="l",col="black", main="random forest with mtr = p^0.5", xlab = "num of trees")
plot(list, mse_rf2,type="l",col="black", main="random forest with mtr = 25", xlab = "num of trees")
plot(list, mse_boosting,type="l",col="green", main="boosting", xlab = "num of trees")
library(MASS)
library(tree)
library(ISLR)
library(randomForest)
forest1 = randomForest(Viability ~ ., model_data, mtry = 7, importantce = TRUE)
y_predict_rf = predict(forest1, newdata = kaggle_data)
#write to file
output_file[,2] = y_predict_rf
write.table(output_file, file ="submission.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(glmnet)
library(Metrics)
require(doMC)
library(data.table)
registerDoMC(cores=4)
source <- read.csv(file="train.csv", header=TRUE, sep=",", stringsAsFactors=FALSE)
rownames(source) <- source[,1]
source[,1] <- NULL #eliminate variable "ID"
source <- data.frame(source)
model_data = source[which(is.na(source["Viability"])== FALSE),] #100 data
kaggle_data = source[which(is.na(source["Viability"])== TRUE),] #20 data
output_file <- read.csv(file="test.csv", header=TRUE, sep=",", stringsAsFactors=FALSE)
source <- read.csv(file="train.csv", header=TRUE, sep=",", stringsAsFactors=FALSE)
rownames(source) <- source[,1]
source[,1] <- NULL #eliminate variable "ID"
source <- data.frame(source)
model_data = source[which(is.na(source["Viability"])== FALSE),] #100 data
kaggle_data = source[which(is.na(source["Viability"])== TRUE),] #20 data
source <- read.csv(file="train.csv", header=TRUE, sep=",", stringsAsFactors=FALSE)
rownames(source) <- source[,1]
source[,1] <- NULL #eliminate variable "ID"
source <- data.frame(source)
model_data = source[which(is.na(source["Viability"])== FALSE),] #100 data
kaggle_data = source[which(is.na(source["Viability"])== TRUE),] #20 data
library(glmnet)
library(Metrics)
require(doMC)
library(data.table)
registerDoMC(cores=4)
source <- read.csv(file="train.csv", header=TRUE, sep=",", stringsAsFactors=FALSE)
rownames(source) <- source[,1]
source[,1] <- NULL #eliminate variable "ID"
source <- data.frame(source)
model_data = source[which(is.na(source["Viability"])== FALSE),] #100 data
kaggle_data = source[which(is.na(source["Viability"])== TRUE),] #20 data
setwd("~/Desktop/2017 Spring/6380/mini2/combinatoric")
source <- read.csv(file="train.csv", header=TRUE, sep=",", stringsAsFactors=FALSE)
rownames(source) <- source[,1]
source[,1] <- NULL #eliminate variable "ID"
source <- data.frame(source)
model_data = source[which(is.na(source["Viability"])== FALSE),] #100 data
kaggle_data = source[which(is.na(source["Viability"])== TRUE),] #20 data
library(MASS)
library(tree)
library(ISLR)
library(randomForest)
forest1 = randomForest(Viability ~ ., model_data, mtry = 7, importantce = TRUE)
y_predict_rf = predict(forest1, newdata = kaggle_data)
#write to file
output_file[,2] = y_predict_rf
write.table(output_file, file ="submission.csv", sep = ",", qmethod = "double", row.names = FALSE)
mlr = lm(Viability ~ ., data = model_data)
predict_value = predict(mlr, kaggle_data) #predict value
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission.csv", sep = ",", qmethod = "double", row.names = FALSE) #the file you want to submit to kaggle
source <- read.csv(file="train.csv", header=TRUE, sep=",", stringsAsFactors=FALSE)
rownames(source) <- source[,1]
source[,1] <- NULL #eliminate variable "ID"
source <- data.frame(source)
model_data = source[which(is.na(source["Viability"])== FALSE),] #100 data
kaggle_data = source[which(is.na(source["Viability"])== TRUE),] #20 data
output_file <- read.csv(file="submission.csv", header=TRUE, sep=",", stringsAsFactors=FALSE)
library(MASS)
library(tree)
library(ISLR)
library(randomForest)
forest1 = randomForest(Viability ~ ., model_data, mtry = 7, importantce = TRUE)
y_predict_rf = predict(forest1, newdata = kaggle_data)
#write to file
output_file[,2] = y_predict_rf
write.table(output_file, file ="submission.csv", sep = ",", qmethod = "double", row.names = FALSE)
setwd("~/Desktop/2017 Spring/6380/mini2/drug2")
require(doMC)
library(data.table)
registerDoMC(cores=4)
source <- read.csv(file="train.csv", header=TRUE, sep=",", stringsAsFactors=FALSE)
rownames(source) <- source[,1]
source[,1] <- NULL #eliminate variable "ID"
source <- data.frame(source)
model_data = source[which(is.na(source["IC50s"])== FALSE),] #542 data
kaggle_data = source[which(is.na(source["IC50s"])== TRUE),] #100 data
output_file <- read.csv(file="submission.csv", header=TRUE, sep=",", stringsAsFactors=FALSE)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = ncol(model_data))
predict_value = predict(forest1, newdata = kaggle_data)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_bagging.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = ncol(model_data)^0.5)
predict_value = predict(forest1, newdata = kaggle_data)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_rf1.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = 25)
predict_value = predict(forest1, newdata = kaggle_data)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_rf2.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(gbm)
boost1 = gbm(IC50s ~ . - Cell.lines, data = model_data, distribution = "gaussian", n.trees = 5000, interaction.depth = 1)
predict_value = predict(boost1, newdata = kaggle_data, n.trees = 5000)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_boosting.csv", sep = ",", qmethod = "double", row.names = FALSE)
View(model_data)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = ncol(model_data)-2)
predict_value = predict(forest1, newdata = kaggle_data)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_bagging.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = (ncol(model_data)-2)^0.5)
predict_value = predict(forest1, newdata = kaggle_data)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_rf1.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = 25)
predict_value = predict(forest1, newdata = kaggle_data)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_rf2.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(gbm)
boost1 = gbm(IC50s ~ . - Cell.lines, data = model_data, distribution = "gaussian", n.trees = 5000, interaction.depth = 1)
predict_value = predict(boost1, newdata = kaggle_data, n.trees = 5000)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_boosting.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = ncol(model_data)-2, n.trees = 5000)
predict_value = predict(forest1, newdata = kaggle_data, n.trees = 5000)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_bagging.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = (ncol(model_data)-2)^0.5, n.trees = 5000)
predict_value = predict(forest1, newdata = kaggle_data, n.trees = 5000)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_rf1.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = 25, n.trees = 5000)
predict_value = predict(forest1, newdata = kaggle_data, n.trees = 5000)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_rf2.csv", sep = ",", qmethod = "double", row.names = FALSE)
par(mfrow =c(1,4))
plot(list, mse_bagging,type="l",col="red",main="bagging", xlab = "num of trees")
plot(list, mse_rf,type="l",col="black", main="random forest with mtr = p^0.5", xlab = "num of trees")
plot(list, mse_rf2,type="l",col="black", main="random forest with mtr = 25", xlab = "num of trees")
plot(list, mse_boosting,type="l",col="green", main="boosting", xlab = "num of trees")
require(doMC)
library(data.table)
registerDoMC(cores=4)
source <- read.csv(file="train.csv", header=TRUE, sep=",", stringsAsFactors=FALSE)
rownames(source) <- source[,1]
source[,1] <- NULL #eliminate variable "ID"
source <- data.frame(source)
model_data = source[which(is.na(source["IC50s"])== FALSE),] #542 data
kaggle_data = source[which(is.na(source["IC50s"])== TRUE),] #100 data
output_file <- read.csv(file="submission.csv", header=TRUE, sep=",", stringsAsFactors=FALSE)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = ncol(model_data)-2, n.trees = 5000)
predict_value = predict(forest1, newdata = kaggle_data, n.trees = 5000)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_bagging.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = (ncol(model_data)-2)^0.5, n.trees = 5000)
predict_value = predict(forest1, newdata = kaggle_data, n.trees = 5000)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_rf1.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = 25, n.trees = 5000)
predict_value = predict(forest1, newdata = kaggle_data, n.trees = 5000)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_rf2.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(gbm)
boost1 = gbm(IC50s ~ . - Cell.lines, data = model_data, distribution = "gaussian", n.trees = 5000, interaction.depth = 1)
predict_value = predict(boost1, newdata = kaggle_data, n.trees = 5000)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_boosting.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(randomForest)
true_y = model_data$IC50s
max_tree_num = 5000
list = seq(1, max_tree_num, by = 100)
mse_bagging = rep(0, length(list))
mse_rf = rep(0, length(list))
mse_rf2 = rep(0, length(list))
mse_boosting = rep(0, length(list))
for (i in c(1:length(list))) {
#bagging
bagging_model = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = ncol(model_data), n.trees = list[i])
mse_bagging[i] = mean(( true_y - predict(bagging_model, newdata = model_data))^2)
#forest 1
rf_model = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = ncol(model_data)^0.5, n.trees = list[i])
mse_rf[i] = mean(( true_y - predict(rf_model, newdata = model_data))^2)
#forest 2
rf_model_2 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = 25, n.trees = list[i])
mse_rf2[i] = mean(( true_y - predict(rf_model_2, newdata = model_data))^2)
#boosting
boost1 = gbm(IC50s ~ . - Cell.lines, data = model_data, distribution = "gaussian", n.trees = list[i], interaction.depth = 1)
mse_boosting[i] = mean(( true_y - predict(boost1, newdata = model_data, n.trees = list[i]))^2)
print(i)
}
library(gbm)
boost1 = gbm(IC50s ~ . - Cell.lines, data = model_data, distribution = "gaussian", n.trees = 5000, interaction.depth = 1)
predict_value = predict(boost1, newdata = kaggle_data, n.trees = 5000)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_boosting.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(gbm)
boost1 = gbm(IC50s ~ . - Cell.lines, data = model_data, distribution = "gaussian", n.trees = 5000, interaction.depth = 1)
predict_value = predict(boost1, newdata = kaggle_data, n.trees = 5000)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_boosting.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(randomForest)
true_y = model_data$IC50s
max_tree_num = 5000
list = seq(1, max_tree_num, by = 100)
mse_bagging = rep(0, length(list))
mse_rf = rep(0, length(list))
mse_rf2 = rep(0, length(list))
mse_boosting = rep(0, length(list))
for (i in c(1:length(list))) {
#bagging
bagging_model = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = ncol(model_data), n.trees = list[i])
mse_bagging[i] = mean(( true_y - predict(bagging_model, newdata = model_data))^2)
#forest 1
rf_model = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = ncol(model_data)^0.5, n.trees = list[i])
mse_rf[i] = mean(( true_y - predict(rf_model, newdata = model_data))^2)
#forest 2
rf_model_2 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = 25, n.trees = list[i])
mse_rf2[i] = mean(( true_y - predict(rf_model_2, newdata = model_data))^2)
#boosting
boost1 = gbm(IC50s ~ . - Cell.lines, data = model_data, distribution = "gaussian", n.trees = list[i], interaction.depth = 1)
mse_boosting[i] = mean(( true_y - predict(boost1, newdata = model_data, n.trees = list[i]))^2)
print(i)
}
par(mfrow =c(2,2))
plot(list, mse_bagging,type="l",col="red",main="bagging", xlab = "num of trees")
plot(list, mse_rf,type="l",col="black", main="random forest with mtr = p^0.5", xlab = "num of trees")
plot(list, mse_rf2,type="l",col="black", main="random forest with mtr = 25", xlab = "num of trees")
plot(list, mse_boosting,type="l",col="green", main="boosting", xlab = "num of trees")
par(mfrow =c(1,4))
plot(list, mse_bagging,type="l",col="red",main="bagging", xlab = "num of trees")
plot(list, mse_rf,type="l",col="black", main="random forest with mtr = p^0.5", xlab = "num of trees")
plot(list, mse_rf2,type="l",col="black", main="random forest with mtr = 25", xlab = "num of trees")
plot(list, mse_boosting,type="l",col="green", main="boosting", xlab = "num of trees")
par(mfrow =c(1,2))
plot(list, mse_bagging,type="l",col="red",main="bagging", xlab = "num of trees")
plot(list, mse_rf,type="l",col="black", main="random forest with mtr = p^0.5", xlab = "num of trees")
plot(list, mse_rf2,type="l",col="black", main="random forest with mtr = 25", xlab = "num of trees")
plot(list, mse_boosting,type="l",col="green", main="boosting", xlab = "num of trees")
par(mfrow =c(1,2))
plot(list, mse_bagging,type="l",col="red",main="bagging", xlab = "num of trees")
plot(list, mse_rf,type="l",col="black", main="random forest with mtr = p^0.5", xlab = "num of trees")
par(mfrow =c(1,2))
plot(list, mse_rf2,type="l",col="black", main="random forest with mtr = 25", xlab = "num of trees")
plot(list, mse_boosting,type="l",col="green", main="boosting", xlab = "num of trees")
png('first.png')
par(mfrow =c(1,2))
plot(list, mse_bagging,type="l",col="red",main="bagging", xlab = "num of trees")
plot(list, mse_rf,type="l",col="black", main="random forest with mtr = p^0.5", xlab = "num of trees")
png('second.png')
par(mfrow =c(1,2))
plot(list, mse_rf2,type="l",col="black", main="random forest with mtr = 25", xlab = "num of trees")
plot(list, mse_boosting,type="l",col="green", main="boosting", xlab = "num of trees")
png(filename = 'first.png')
par(mfrow =c(1,2))
plot(list, mse_bagging,type="l",col="red",main="bagging", xlab = "num of trees")
plot(list, mse_rf,type="l",col="black", main="random forest with mtr = p^0.5", xlab = "num of trees")
dev.off()
png(filename = 'second.png')
par(mfrow =c(1,2))
plot(list, mse_rf2,type="l",col="black", main="random forest with mtr = 25", xlab = "num of trees")
plot(list, mse_boosting,type="l",col="green", main="boosting", xlab = "num of trees")
dev.off()
par(mfrow =c(1,2))
plot(list, mse_bagging,type="l",col="red",main="bagging", xlab = "num of trees")
plot(list, mse_rf,type="l",col="black", main="random forest with mtr = p^0.5", xlab = "num of trees")
par(mfrow =c(1,2))
plot(list, mse_rf2,type="l",col="black", main="random forest with mtr = 25", xlab = "num of trees")
plot(list, mse_boosting,type="l",col="green", main="boosting", xlab = "num of trees")
par(mfrow=c(2,2))
plot(list, mse_bagging,type="l",col="red",main="bagging", xlab = "num of trees")
plot(list, mse_rf,type="l",col="black", main="random forest with mtr = p^0.5", xlab = "num of trees")
plot(list, mse_rf2,type="l",col="black", main="random forest with mtr = 25", xlab = "num of trees")
plot(list, mse_boosting,type="l",col="green", main="boosting", xlab = "num of trees")
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = ncol(model_data), n.trees = 5000)
predict_value = predict(forest1, newdata = kaggle_data)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_bagging.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = ncol(model_data)^0.5, n.trees = 5000)
predict_value = predict(forest1, newdata = kaggle_data)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_rf1.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = 25, n.trees = 5000)
predict_value = predict(forest1, newdata = kaggle_data)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_rf2.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(gbm)
boost1 = gbm(IC50s ~ . - Cell.lines, data = model_data, distribution = "gaussian", n.trees = 5000, interaction.depth = 1)
predict_value = predict(boost1, newdata = kaggle_data, n.trees = 5000)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_boosting.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = 25, n.trees = 5000, importance = TRUE)
predict_value = predict(forest1, newdata = kaggle_data)
importance (rf.boston )
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_rf2.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = 25, n.trees = 5000, importance = TRUE)
predict_value = predict(forest1, newdata = kaggle_data)
importance (forest1 )
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_rf2.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = 25, n.trees = 5000, importance = TRUE)
predict_value = predict(forest1, newdata = kaggle_data)
importance (forest1)
varImpPlot (forest1)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_rf2.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = 25, n.trees = 5000, importance = TRUE)
predict_value = predict(forest1, newdata = kaggle_data)
importance (forest1)
varImpPlot (forest1)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_rf2.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = 25, n.trees = 5000, importance = TRUE)
predict_value = predict(forest1, newdata = kaggle_data)
importance (forest1)
varImpPlot (forest1)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_rf2.csv", sep = ",", qmethod = "double", row.names = FALSE)
library(randomForest)
forest1 = randomForest(IC50s ~ . - Cell.lines, model_data, mtry = ncol(model_data), n.trees = 5000, importance = TRUE)
predict_value = predict(forest1, newdata = kaggle_data)
importance (forest1)
varImpPlot (forest1)
#write to file
output_file[,2] = predict_value
write.table(output_file, file ="submission_bagging.csv", sep = ",", qmethod = "double", row.names = FALSE)
importance(forest1)
importance(forest1) > 0
count(importance(forest1) > 0)
count
